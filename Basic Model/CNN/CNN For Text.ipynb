{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.feature_extraction.text import *\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pickle.load(open(\"/Users/Maximus/downloads/Data_12_03\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Maximus/anaconda/envs/tensorflow/lib/python2.7/site-packages/pandas/core/generic.py:3295: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    }
   ],
   "source": [
    "train_data = data.loc[data.Date < '2009-01-01', :]\n",
    "dev_data = data.loc[(data.Date >= '2009-01-01') & (data.Date <= '2010-12-31'), :]\n",
    "test_data = data.loc[data.Date >= '2011-01-01', :]\n",
    "\n",
    "train_label = train_data.label\n",
    "dev_label = dev_data.label\n",
    "test_label = test_data.label\n",
    "\n",
    "#train_text_features.shape\n",
    "train_data['Surprise'].fillna(0, inplace=True)\n",
    "dev_data['Surprise'].fillna(0, inplace=True)\n",
    "#train_data.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13      UP\n",
       "14      UP\n",
       "15    DOWN\n",
       "16      UP\n",
       "17      UP\n",
       "Name: label, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Maximus/anaconda/envs/tensorflow/lib/python2.7/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "train_data['label2'] = train_data['label'].apply(lambda x: 1 if str(x) == 'UP' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17500,)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['label2'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(min_df=1, stop_words='english')\n",
    "train_text_features = vectorizer.fit_transform(train_data.bow)\n",
    "\n",
    "dev_text_features = vectorizer.transform(dev_data.bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_data_train = np.append(train_text_features.toarray(),\\\n",
    "                           np.array(train_data.Surprise).reshape(len(train_data.Surprise),1), 1)\n",
    "all_data_dev = np.append(dev_text_features.toarray(),\\\n",
    "                         np.array(dev_data.Surprise).reshape(len(dev_data.Surprise),1), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()  # clear away any leftovers from previous executions\n",
    "\n",
    "input_dim = all_data_train.shape[1]\n",
    "#train_label\n",
    "\n",
    "X_ = tf.placeholder(tf.float32, shape=[None, input_dim], name=\"X\")\n",
    "y_ = tf.placeholder(tf.float32, shape=[None], name=\"y\")\n",
    "\n",
    "# Variables for the parameters of our model\n",
    "with tf.name_scope('model_parameters'):\n",
    "    w_ = tf.Variable(tf.zeros([input_dim, 1], dtype=tf.float32), name=\"w\")\n",
    "    b_ = tf.Variable(0.0, dtype=tf.float32, name=\"b\")\n",
    "\n",
    "# Output layer: \\sigma(Xw + b)\n",
    "with tf.name_scope('logit'):\n",
    "    logits_ = tf.squeeze(tf.matmul(X_, w_)) + b_\n",
    "with tf.name_scope('pred_proba'):\n",
    "    pred_proba_ = tf.sigmoid(logits_)\n",
    "\n",
    "# Cost function\n",
    "with tf.name_scope('cost_function'):\n",
    "    loss_ = tf.nn.sigmoid_cross_entropy_with_logits(logits_, y_, name='loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Gradient descent training\n",
    "with tf.name_scope('training'):\n",
    "    alpha_ = tf.placeholder(tf.float32, name=\"learning_rate\")\n",
    "    optimizer_ = tf.train.GradientDescentOptimizer(alpha_)\n",
    "    train_step_ = optimizer_.minimize(loss_)\n",
    "\n",
    "# Initializer step\n",
    "init_ = tf.initialize_all_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iter 0] Average cost: 0.693\n",
      "[iter 10] Average cost: 19639.211\n",
      "[iter 20] Average cost: 2735.646\n",
      "[iter 30] Average cost: 21331.093\n",
      "[iter 40] Average cost: 2645.974\n",
      "[iter 50] Average cost: 13573.046\n",
      "[iter 60] Average cost: 2700.362\n",
      "[iter 70] Average cost: 15810.444\n",
      "[iter 80] Average cost: 3316.338\n",
      "[iter 90] Average cost: 21808.962\n",
      "\n",
      "Accuracy: 0.624\n",
      "Mean cross-entropy loss: 2739.421\n"
     ]
    }
   ],
   "source": [
    "max_steps = 100\n",
    "print_every = max_steps / 10\n",
    "alpha = 0.01  # learning rate\n",
    "\n",
    "# We'll constrain this to run on CPU, as GPUs aren't very efficient\n",
    "# on a model this small.\n",
    "session = tf.Session(config=tf.ConfigProto(device_filters=\"/cpu:0\"))\n",
    "session.run(init_)  # initialize variables for this session\n",
    "\n",
    "\n",
    "for i in xrange(max_steps):          \n",
    "    # Run a single gradient descent step\n",
    "    c, p, _ = session.run([loss_, pred_proba_, train_step_],\n",
    "                           feed_dict={X_: all_data_train, y_: train_data.label2, alpha_: alpha})\n",
    "        \n",
    "    if (i % print_every == 0):\n",
    "        avg_cost = sum(c) / len(train_data.label2)\n",
    "        print \"[iter %d] Average cost: %.03f\" % (i, avg_cost)\n",
    "        \n",
    "\n",
    "# Run model over training set one last time\n",
    "costs, y_pred = session.run([loss_, pred_proba_], \n",
    "                            feed_dict={X_: all_data_train, y_: train_data.label2})\n",
    "\n",
    "print \"\"\n",
    "print \"Accuracy: %.03f\" % np.mean(train_data.label2 == (y_pred >= 0.5))\n",
    "print \"Mean cross-entropy loss: %.03f\" % np.mean(costs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plot_model(X, y, lambda X: session.run(pred_proba_, feed_dict={X_:X}))\n",
    "plt.title(\"%d steps (final)\" % max_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nano\n"
     ]
    }
   ],
   "source": [
    "import convol_net as CNN\n",
    "CNN.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
