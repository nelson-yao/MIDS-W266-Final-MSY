{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division \n",
    "# This tells matplotlib not to try opening a new window for each plot.\n",
    "#%matplotlib inline\n",
    "\n",
    "# General libraries.\n",
    "import os\n",
    "import codecs\n",
    "import json\n",
    "import csv\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import glob\n",
    "import pickle\n",
    "import time\n",
    "# SK-learn libraries for learning.\n",
    "import sklearn\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# SK-learn libraries for evaluation.\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# SK-learn library for importing the newsgroup data.\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "# SK-learn libraries for feature extraction from text.\n",
    "from sklearn.feature_extraction.text import *\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data=pickle.load(open(\"/Users/meaneylab/Box Sync/266/FinalProject/Fulldata_wY\", 'rb'))\n",
    "data=data.drop([\"Unnamed: 0\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load previously saved lemmatized text, see \" Lemmatizing Texts.ipynb \"\n",
    "lemmatized_text=pickle.load(open(\"/Users/meaneylab/Box Sync/266/FinalProject/Text_lemmatized\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u\"TEXT : Check the appropriate box below if the Form 8-K file be intend to simultaneously satisfy the file obligation of the registrant under any of the follow provision ( General Instruction A.2 . below ) : see Item 2.02 Results of Operations and Financial Condition On December 17 , 2009 , Accenture issue a press release announce financial result for its first quarter of fiscal year 2010 , which fiscal quarter end on November 30 , 2009 . A copy of the press release be attach hereto as Exhibit 99.1 . All information in the press release be furnish but not file . Non-GAAP Financial Information In the attach press release Accenture disclose the follow non-GAAP financial measure : Reconciliations of these non-GAAP financial measure to the most directly comparable financial measure calculate and present in accordance with GAAP be include in the press release . While Accenture 's management believe that this non-GAAP financial information be useful in evaluate Accenture 's operations , this i\""
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatized_text[0][0:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37503, 33530)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer1=CountVectorizer(stop_words='english', min_df=10)\n",
    "text_vector=vectorizer1.fit_transform(lemmatized_text)\n",
    "text_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(text_vector, open(\"/Users/meaneylab/Box Sync/266/FinalProject/Text_vector_lemmatized\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37503, 3000)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##  select top features using feature selection packages\n",
    "ktop=SelectKBest(chi2, k=3000).fit_transform(text_vector, labels)\n",
    "ktop.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished in 364.7 seconds\n"
     ]
    }
   ],
   "source": [
    "## Non-negative factorization of the top unigram features, with 100 dimensions\n",
    "start=time.time()\n",
    "model100 = NMF(n_components=100, init='random', random_state=1, alpha=.1, l1_ratio=.5)\n",
    "topVec100 = model100.fit_transform(ktop)\n",
    "print(\"Finished in {:3.1f} seconds\".format(time.time()-start))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(topVec100,open(\"/Users/meaneylab/Box Sync/266/FinalProject/TopVec100_lemmatized\", 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in previously-saved results of NMF text vectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "topVec100=pickle.load(open(\"/Users/meaneylab/Box Sync/266/FinalProject/TopVec100_lemmatized\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Surprise</th>\n",
       "      <th>Date</th>\n",
       "      <th>release_time_type</th>\n",
       "      <th>label</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.08</td>\n",
       "      <td>2009-12-17 00:00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0872788</td>\n",
       "      <td>0.00243483</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000390139</td>\n",
       "      <td>0.00306087</td>\n",
       "      <td>0.0350284</td>\n",
       "      <td>0.587139</td>\n",
       "      <td>0.00585252</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0229607</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0183246</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25</td>\n",
       "      <td>2009-12-17 00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>UP</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.876</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00106202</td>\n",
       "      <td>0.00218452</td>\n",
       "      <td>0.0945596</td>\n",
       "      <td>0.283774</td>\n",
       "      <td>0.0021018</td>\n",
       "      <td>0.0881531</td>\n",
       "      <td>0</td>\n",
       "      <td>0.334748</td>\n",
       "      <td>0.0215783</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.38</td>\n",
       "      <td>2009-12-17 00:00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>STAY</td>\n",
       "      <td>0.192988</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00152716</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0371115</td>\n",
       "      <td>0.392072</td>\n",
       "      <td>0.0324689</td>\n",
       "      <td>0.0151895</td>\n",
       "      <td>0</td>\n",
       "      <td>0.137712</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.77</td>\n",
       "      <td>2009-12-17 00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>0.205799</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0129627</td>\n",
       "      <td>0.020562</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.138232</td>\n",
       "      <td>0.0270192</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.94</td>\n",
       "      <td>2009-12-17 00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>UP</td>\n",
       "      <td>0.195125</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.358698</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00254715</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00669368</td>\n",
       "      <td>1.24026</td>\n",
       "      <td>0.0141996</td>\n",
       "      <td>0.00149622</td>\n",
       "      <td>0</td>\n",
       "      <td>0.262501</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 104 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Surprise                 Date release_time_type label         0  1  2  \\\n",
       "0     3.08  2009-12-17 00:00:00                 3  DOWN         0  0  0   \n",
       "1       25  2009-12-17 00:00:00                 1    UP         0  0  0   \n",
       "2     2.38  2009-12-17 00:00:00                 3  STAY  0.192988  0  0   \n",
       "3     3.77  2009-12-17 00:00:00                 1  DOWN  0.205799  0  0   \n",
       "4     6.94  2009-12-17 00:00:00                 1    UP  0.195125  0  0   \n",
       "\n",
       "           3           4  5 ...           90          91          92  \\\n",
       "0  0.0872788  0.00243483  0 ...  0.000390139  0.00306087   0.0350284   \n",
       "1      2.876           0  0 ...   0.00106202  0.00218452   0.0945596   \n",
       "2          0  0.00152716  0 ...            0           0   0.0371115   \n",
       "3          0           0  0 ...            0   0.0129627    0.020562   \n",
       "4   0.358698           0  0 ...   0.00254715           0  0.00669368   \n",
       "\n",
       "         93          94          95         96        97         98 99  \n",
       "0  0.587139  0.00585252           0  0.0229607         0  0.0183246  0  \n",
       "1  0.283774   0.0021018   0.0881531          0  0.334748  0.0215783  0  \n",
       "2  0.392072   0.0324689   0.0151895          0  0.137712          0  0  \n",
       "3         0           0           0          0  0.138232  0.0270192  0  \n",
       "4   1.24026   0.0141996  0.00149622          0  0.262501          0  0  \n",
       "\n",
       "[5 rows x 104 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alldata=pd.DataFrame(np.hstack((data.as_matrix(), topVec100)))\n",
    "alldata.columns=np.array(['Company', 'ticker', 'Surprise', 'Reported_EPS', 'Consensus_EPS',\n",
    "       'Date', 'timestamp', 'bow', 'items', 'text', 'orig_file',\n",
    "       'release_time_type', 'return', 'stock_performance',\n",
    "       'market_performance', 'normalized_performance', 'label']+range(100))\n",
    "allfeatures=alldata.drop([\"Company\", \"ticker\",'bow', 'orig_file', 'stock_performance', \\\n",
    "                              'market_performance', 'normalized_performance', 'text',\\\n",
    "                          'timestamp' , 'Reported_EPS', 'Consensus_EPS', \"items\", \"return\"], axis=1).dropna(axis=0, how=\"any\")\n",
    "allfeatures.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data = allfeatures.loc[allfeatures.Date < pd.to_datetime('2009-01-01'), :].drop(['Date', 'label'], axis=1)\n",
    "dev_data = allfeatures.loc[(allfeatures.Date >= pd.to_datetime('2009-01-01')) & \\\n",
    "                           (allfeatures.Date <= pd.to_datetime('2010-12-31')), :].drop(['Date', 'label'], axis=1)\n",
    "test_data = allfeatures.loc[allfeatures.Date >= pd.to_datetime('2011-01-01'), :].drop(['Date'], axis=1)\n",
    "test_data=test_data[test_data['release_time_type']!=pd.Timestamp('2012-08-07 09:30:00')]\n",
    "test_label=test_data['label']\n",
    "test_data=test_data.drop([\"label\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_label=allfeatures.loc[allfeatures.Date < pd.to_datetime('2009-01-01'), \"label\"]\n",
    "dev_label = allfeatures.loc[(allfeatures.Date >= pd.to_datetime('2009-01-01')) & \\\n",
    "                           (allfeatures.Date <= pd.to_datetime('2010-12-31')), 'label']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17449, 102) (9715, 102) (10191, 102)\n"
     ]
    }
   ],
   "source": [
    "print train_data.shape, dev_data.shape, test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf=RandomForestClassifier(n_estimators=2000)\n",
    "model=rf.fit(train_data, train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pickle.dump(model, open(\"/Users/meaneylab/Box Sync/266/FinalProject/RF_unlemmatized_2000Tree\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_lem=rf.fit(train_data, train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pickle.dump(model, open(\"/Users/meaneylab/Box Sync/266/FinalProject/RF_lemmatized_2000Tree\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.299228    0.01791045  0.05898096]\n",
      " [ 0.16222337  0.04632012  0.08378796]\n",
      " [ 0.13772517  0.02367473  0.17014925]]\n",
      "F-score : 0.481\n",
      "Accuracy : 0.516\n"
     ]
    }
   ],
   "source": [
    "# Dev set accuracy\n",
    "preds_dev = model_lem.predict(dev_data)\n",
    "F_Score_dev = metrics.f1_score(dev_label, preds, average='weighted')\n",
    "pred_probas_dev = model_lem.predict_proba(dev_data)\n",
    "#model_output(pred_probas, F_Score, preds)\n",
    "conf_dev=confusion_matrix(dev_label.values, preds_dev,labels=[\"UP\", \"STAY\", \"DOWN\"] , )\n",
    "print(conf_dev/len(preds_dev))\n",
    "print(\"F-score : {:3.3f}\".format(F_Score_dev))\n",
    "print(\"Accuracy : {:3.3f}\".format(np.sum(preds_dev==dev_label)/len(dev_label)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.1627907   0.06083799  0.10028456]\n",
      " [ 0.08419193  0.10695712  0.13757237]\n",
      " [ 0.04631538  0.0456285   0.25542145]]\n",
      "F-score : 0.512\n",
      "Accuracy : 0.525\n"
     ]
    }
   ],
   "source": [
    "# Test set accuracy\n",
    "preds_test = model.predict(test_data)\n",
    "F_Score_test = metrics.f1_score(test_label, preds_test, average='weighted')\n",
    "pred_probas = model.predict_proba(test_data)\n",
    "#model_output(pred_probas, F_Score, preds)\n",
    "conf_test=confusion_matrix(test_label, preds_test)\n",
    "print(conf_test/len(preds_test))\n",
    "print(\"F-score : {:3.3f}\".format(F_Score_test))\n",
    "print(\"Accuracy : {:3.3f}\".format(np.sum(preds_test==test_label)/len(test_label)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Method for printing out Roc curve\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "def model_output(pred_probas, F_Score, preds, title=''):\n",
    "    print ((\"Number of positive prediction: %d\") % (preds.sum()))\n",
    "    print (\"Model F-Score = %0.4f \"%(F_Score))  #Sum up Squared Weights\n",
    "    accuracy = np.where(preds==dev_labels, 1, 0).sum() / float(len(dev_labels))\n",
    "    print (\"Accuracy = %0.4f\"    % (accuracy))\n",
    "    print ('precision_score: %f'  % metrics.precision_score(dev_labels, preds))\n",
    "    print ('recall_score: %0.4f' % metrics.recall_score(dev_labels, preds))\n",
    "    #print ('roc_auc_score: %0.4f'% metrics.roc_auc_score(dev_labels, preds, 'weighted'))\n",
    "    \n",
    "    # to reproduce from Kaggle, dont change weighted argument, just use default\n",
    "    # http://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html\n",
    "    # https://github.com/benhamner/Metrics/blob/master/Python/ml_metrics/auc.py\n",
    "    \n",
    "    # don't use 0 or 1, instead use the probabilities but think about it as a ranking score\n",
    "    # with auc, just want positive examples ranked over the negative examples,\n",
    "    # does not matter if .99 > .90 or .11 vs. .01\n",
    "    print ('roc_auc_score: %0.4f'% metrics.roc_auc_score(dev_labels, pred_probas[:,1]))\n",
    "    \n",
    "    # if just printing, use roc_auc_score as above, computes the roc all at once\n",
    "    # if plotting, use roc_auc as below, computes one step at a time\n",
    "    # returns the scores at each threshold\n",
    "    # https://hsto.org/files/54b/611/188/54b611188a8b4b2a9ca1e41884f21a3f.png\n",
    "    \n",
    "    # add thresholds\n",
    "    \n",
    "    fpr,tpr,thresholds = roc_curve(dev_labels, pred_probas[:,1])\n",
    "    table_of_thresholds = pd.DataFrame({'fpr': fpr, 'tpr': tpr, 'thresholds': thresholds})\n",
    "    roc_auc = auc(fpr,tpr)\n",
    "    plt.plot(fpr,tpr,label='area = %.4f' %roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.title(title)\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.legend(loc='lower right')\n",
    "    #return table_of_thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
